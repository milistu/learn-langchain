{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `load_dotenv(find_dotenv())` to find and load `.env` file. <br>\n",
    "Why? ðŸ¤” <br> \n",
    "If your environemnt file is not located in the root of your project we can still access it. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs\n",
    "LLMs [documentation](https://python.langchain.com/docs/modules/model_io/llms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"], organization=os.environ[\"OPENAI_ORGANIZATION\"]\n",
    ")\n",
    "chat_model = ChatOpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    organization=os.environ[\"OPENAI_ORGANIZATION\"],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM objects take string as input and output string. <br>\n",
    "The ChatModel objects take a list of messages as input and output a message. <br>\n",
    "For a deeper conceptual explanation of this difference please see [this documentation](https://python.langchain.com/docs/modules/model_io/concepts). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LLM response: \\n\\nNo, I am a digital AI created by humans.'\n",
      "\"LLM response type: <class 'str'>\"\n",
      "'----------------------------------------------------------------------------------------------------'\n",
      "(\"Chat Model response: content='No, I am an artificial intelligence created by \"\n",
      " \"humans to assist with answering questions and providing information.' \"\n",
      " \"response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': \"\n",
      " \"12, 'total_tokens': 31}, 'model_name': 'gpt-3.5-turbo', \"\n",
      " \"'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': \"\n",
      " 'None}')\n",
      "\"Chat Model response type: <class 'langchain_core.messages.ai.AIMessage'>\"\n"
     ]
    }
   ],
   "source": [
    "text = \"Are you an Alien?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "response = llm.invoke(text)\n",
    "pprint(f\"LLM response: {response}\")\n",
    "pprint(f\"LLM response type: {type(response)}\")\n",
    "\n",
    "pprint(\"-\" * 100)\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "pprint(f\"Chat Model response: {response}\")\n",
    "pprint(f\"Chat Model response type: {type(response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with raw LLMs is that they donâ€™t remember the history of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='Your previous question was \"What is your favorite color?\"', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})\n"
     ]
    }
   ],
   "source": [
    "response = chat_model.invoke(\"What was my previous question?\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "Chains [documentation](https://python.langchain.com/docs/modules/chains)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add memory manually \n",
    "Following their current documentation and supported modules we can create a memory modeul and add history manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see chain's process of toughts we neeed to activate **debugging** mode and **verbose**.\n",
    "> ðŸ“Ž **Note**: For some reason **verbose** is not working so we can use debug mode. Debug mode outputs a lot of text that is not important to us now so we will continu using basic output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(value=False)\n",
    "set_verbose(value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='No, I am not an alien. I am a computer program designed to assist and provide information to users. How can I help you today?', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 22, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"Are you an Alien?\"}\n",
    "\n",
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(inputs, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Are you an Alien?'),\n",
       "  AIMessage(content='No, I am not an alien. I am a computer program designed to assist and provide information to users. How can I help you today?')]}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your previous question was \"Are you an Alien?\" Is there anything else you would like to ask or discuss?', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 65, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What was my previous question?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add memory automatically\n",
    "We can use chain class that support automatic history tracking but they may be unsupported in the future.\n",
    "\n",
    "Here we can set `verbose` in chain directly and it will work.\n",
    "\n",
    "IMO this approach is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    organization=os.environ[\"OPENAI_ORGANIZATION\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model, verbose=True, memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Are you an Alien?!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, I am not an alien. I am an artificial intelligence created by humans to assist with various tasks and provide information. I do not have a physical form like an alien would.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Are you an Alien?!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the prompt, we see now that there is a bit more then our simple prompt. <br>\n",
    "We have a system prompt, the history of the conversation, and the humanâ€™s question. <br>\n",
    "The system prompt allows us to give the LLM more context on what needs to be done. <br>\n",
    "Letâ€™s see if it remembers: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Are you an Alien?!\n",
      "AI: No, I am not an alien. I am an artificial intelligence created by humans to assist with various tasks and provide information. I do not have a physical form like an alien would.\n",
      "Human: What was my previous question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"Are you an Alien?!\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was my previous question?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "Prompt template [documetation](https://python.langchain.com/docs/modules/model_io/prompts/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LangChain, we can make the process of creating prompts easier by using prompt templates.\n",
    "\n",
    "Let's make a simple prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['category'], template='\\nReturn all the subcategories of the following category\\n\\n{category}\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Return all the subcategories of the following category\n",
    "\n",
    "{category}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"category\"], template=template)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Category\" serves as an input variable activated upon executing the chain.\n",
    "\n",
    "Proceed to incorporate it into a chain. For this purpose, we employ the LLMChain, which stands as the most fundamental chain available for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Clustering\\n- Classification\\n- Regression\\n- Dimensionality Reduction'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat_model, prompt=prompt, verbose=True)\n",
    "\n",
    "chain.run(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also split the prompts into **system** and **human** categories. \n",
    "\n",
    "This approach is useful when creating chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are a helpful assistant who generate comma separated lists.\n",
    "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
    "ONLY return comma separated and nothing more!\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{category}\"\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_message = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can combine the 2 prompts into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['category'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are a helpful assistant who generate comma separated lists.\\nA user will only pass a category and you should generate subcategories of that category in a comma separated list.\\nONLY return comma separated and nothing more!\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category'], template='{category}'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages=[system_message, human_message])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Clustering, Classification, Regression, Dimensionality Reduction'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat_model, prompt=prompt, verbose=True)\n",
    "\n",
    "response = chain.run(\"Machine Learning\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach allows us to better manage the output from the LLM, but we can enhance this further by using an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output  parser\n",
    "Output parser [documentation](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s overwrite the base output parser and generate Python lists from the LLMâ€™s response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        output = text.strip().split(\",\")\n",
    "        output = [element.strip() for element in output]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chat_model, prompt=prompt, output_parser=CommaSeparatedParser(), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['Supervised Learning',\n",
      " 'Unsupervised Learning',\n",
      " 'Reinforcement Learning',\n",
      " 'Deep Learning',\n",
      " 'Natural Language Processing',\n",
      " 'Computer Vision',\n",
      " 'Clustering',\n",
      " 'Classification',\n",
      " 'Regression',\n",
      " 'Dimensionality Reduction']\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"Machine Learning\")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass to the chain multiple inputs at once with `apply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: food\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: drinks\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: colors\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[{'text': ['fruits', 'vegetables', 'grains', 'dairy', 'protein', 'sweets']},\n",
      " {'text': ['alcoholic',\n",
      "           'non-alcoholic',\n",
      "           'hot',\n",
      "           'cold',\n",
      "           'carbonated',\n",
      "           'caffeinated']},\n",
      " {'text': ['red',\n",
      "           'orange',\n",
      "           'yellow',\n",
      "           'green',\n",
      "           'blue',\n",
      "           'indigo',\n",
      "           'violet',\n",
      "           'pink',\n",
      "           'purple',\n",
      "           'black',\n",
      "           'white',\n",
      "           'gray',\n",
      "           'brown']}]\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"category\": \"food\"},\n",
    "    {\"category\": \"drinks\"},\n",
    "    {\"category\": \"colors\"},\n",
    "]\n",
    "response = chain.apply(input_list)\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'pink',\n",
       " 'purple',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray',\n",
       " 'brown']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[2][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequence\n",
    "Sequential chains [documentation](https://python.langchain.com/docs/modules/chains/foundational/sequential_chains)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also link chains together, forming a sequence where the output from one chain serves as the input for the next. \n",
    "\n",
    "To automate blog writing, we set up two chains: a title chain and a sections chain. Let's start with the title chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Unraveling the Wonders of Machine Learning: A Beginner\\'s Guide\"'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a subject, your job is to return the best title for a blog. \n",
    "Subject: {subject}\n",
    "Title:\n",
    "\"\"\"\n",
    "\n",
    "title_chain = LLMChain.from_string(llm=chat_model, template=title_template)\n",
    "\n",
    "title_chain.run(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In this blog, we will delve into the fascinating world of machine learning, '\n",
      " 'a rapidly growing field that is revolutionizing industries and changing the '\n",
      " 'way we interact with technology. Whether you are a complete novice or have '\n",
      " \"some basic knowledge of the subject, this beginner's guide will provide you \"\n",
      " 'with a comprehensive overview of machine learning and its applications.\\n'\n",
      " '\\n'\n",
      " 'Section 1: What is Machine Learning?\\n'\n",
      " 'Machine learning is a subset of artificial intelligence that focuses on the '\n",
      " 'development of algorithms and statistical models that enable computers to '\n",
      " 'learn and make decisions without being explicitly programmed. In simple '\n",
      " 'terms, it is the process of teaching a computer to recognize patterns in '\n",
      " 'data and make predictions based on those patterns. This allows machines to '\n",
      " 'improve their performance over time without human intervention.\\n'\n",
      " '\\n'\n",
      " 'Section 2: Types of Machine Learning\\n'\n",
      " 'There are three main types of machine learning: supervised learning, '\n",
      " 'unsupervised learning, and reinforcement learning. Supervised learning '\n",
      " 'involves training a model on labeled data, where the correct answers are '\n",
      " 'provided. Unsupervised learning, on the other hand, involves training a '\n",
      " 'model on unlabeled data, allowing it to find patterns and relationships on '\n",
      " 'its own. Reinforcement learning is a type of machine learning where an agent '\n",
      " 'learns to make decisions by interacting with its environment and receiving '\n",
      " 'rewards or penalties based on its actions.\\n'\n",
      " '\\n'\n",
      " 'Section 3: Applications of Machine Learning\\n'\n",
      " 'Machine learning has a wide range of applications across various industries, '\n",
      " 'including healthcare, finance, marketing, and more. In healthcare, machine '\n",
      " 'learning is used to analyze medical images, predict patient outcomes, and '\n",
      " 'personalize treatment plans. In finance, it is used for fraud detection, '\n",
      " 'risk assessment, and algorithmic trading. In marketing, machine learning is '\n",
      " 'used to analyze customer behavior, personalize recommendations, and optimize '\n",
      " 'advertising campaigns.\\n'\n",
      " '\\n'\n",
      " 'Section 4: Getting Started with Machine Learning\\n'\n",
      " 'If you are interested in learning more about machine learning, there are '\n",
      " 'plenty of resources available to help you get started. Online courses, '\n",
      " 'tutorials, and books can provide you with the foundational knowledge you '\n",
      " 'need to begin your journey into this exciting field. Additionally, there are '\n",
      " 'many open-source tools and libraries, such as TensorFlow and scikit-learn, '\n",
      " 'that can help you build and train machine learning models.\\n'\n",
      " '\\n'\n",
      " 'Section 5: Conclusion\\n'\n",
      " 'Machine learning is a powerful tool that has the potential to transform the '\n",
      " 'way we live and work. By understanding the basics of machine learning and '\n",
      " 'exploring its applications, you can gain valuable insights into this '\n",
      " 'cutting-edge technology and its impact on society. Whether you are a '\n",
      " \"student, a professional, or simply curious about the field, this beginner's \"\n",
      " 'guide will equip you with the knowledge and resources you need to unravel '\n",
      " 'the wonders of machine learning.')\n"
     ]
    }
   ],
   "source": [
    "sections_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write sections for a blog.\n",
    "Title: {title}\n",
    "Synopsis:\n",
    "\"\"\"\n",
    "\n",
    "sections_chain = LLMChain.from_string(llm=chat_model, template=sections_template)\n",
    "\n",
    "title = \"Unraveling the Wonders of Machine Learning: A Beginner's Guide\"\n",
    "\n",
    "pprint(sections_chain.run(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s now combine those two chains by passing them as a list to the simple sequential chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Unraveling the Wonders of Machine Learning: A Comprehensive Guide\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIn this blog, we will delve into the fascinating world of machine learning, exploring its various applications, techniques, and potential impact on society. From self-driving cars to personalized recommendations on streaming platforms, machine learning is revolutionizing the way we interact with technology. Join us as we unravel the wonders of this cutting-edge field and discover how it is shaping the future of artificial intelligence.\n",
      "\n",
      "Section 1: Introduction to Machine Learning\n",
      "Machine learning is a subset of artificial intelligence that focuses on developing algorithms and models that can learn from and make predictions or decisions based on data. By analyzing patterns and trends in large datasets, machine learning algorithms can identify insights and make predictions without being explicitly programmed to do so. This section will provide an overview of the different types of machine learning, including supervised learning, unsupervised learning, and reinforcement learning, as well as the key concepts and terminology used in the field.\n",
      "\n",
      "Section 2: Applications of Machine Learning\n",
      "Machine learning has a wide range of applications across various industries, from healthcare and finance to marketing and entertainment. In this section, we will explore some of the most exciting and innovative uses of machine learning, such as natural language processing, computer vision, and predictive analytics. We will also discuss how machine learning is being used to improve efficiency, accuracy, and decision-making in areas such as fraud detection, customer service, and personalized recommendations.\n",
      "\n",
      "Section 3: Techniques and Algorithms in Machine Learning\n",
      "There are many different techniques and algorithms used in machine learning, each with its own strengths and weaknesses. In this section, we will provide an overview of some of the most commonly used algorithms, such as linear regression, decision trees, support vector machines, and neural networks. We will also discuss the importance of data preprocessing, feature engineering, and model evaluation in the machine learning pipeline, as well as the ethical considerations and challenges associated with developing and deploying machine learning systems.\n",
      "\n",
      "Section 4: The Future of Machine Learning\n",
      "As machine learning continues to advance and evolve, the possibilities for its future are endless. In this final section, we will explore some of the emerging trends and technologies in machine learning, such as deep learning, transfer learning, and federated learning. We will also discuss the potential impact of machine learning on society, including issues related to bias, privacy, and job displacement. By understanding the wonders of machine learning and its implications for the future, we can better prepare ourselves for the opportunities and challenges that lie ahead.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('In this blog, we will delve into the fascinating world of machine learning, '\n",
      " 'exploring its various applications, techniques, and potential impact on '\n",
      " 'society. From self-driving cars to personalized recommendations on streaming '\n",
      " 'platforms, machine learning is revolutionizing the way we interact with '\n",
      " 'technology. Join us as we unravel the wonders of this cutting-edge field and '\n",
      " 'discover how it is shaping the future of artificial intelligence.\\n'\n",
      " '\\n'\n",
      " 'Section 1: Introduction to Machine Learning\\n'\n",
      " 'Machine learning is a subset of artificial intelligence that focuses on '\n",
      " 'developing algorithms and models that can learn from and make predictions or '\n",
      " 'decisions based on data. By analyzing patterns and trends in large datasets, '\n",
      " 'machine learning algorithms can identify insights and make predictions '\n",
      " 'without being explicitly programmed to do so. This section will provide an '\n",
      " 'overview of the different types of machine learning, including supervised '\n",
      " 'learning, unsupervised learning, and reinforcement learning, as well as the '\n",
      " 'key concepts and terminology used in the field.\\n'\n",
      " '\\n'\n",
      " 'Section 2: Applications of Machine Learning\\n'\n",
      " 'Machine learning has a wide range of applications across various industries, '\n",
      " 'from healthcare and finance to marketing and entertainment. In this section, '\n",
      " 'we will explore some of the most exciting and innovative uses of machine '\n",
      " 'learning, such as natural language processing, computer vision, and '\n",
      " 'predictive analytics. We will also discuss how machine learning is being '\n",
      " 'used to improve efficiency, accuracy, and decision-making in areas such as '\n",
      " 'fraud detection, customer service, and personalized recommendations.\\n'\n",
      " '\\n'\n",
      " 'Section 3: Techniques and Algorithms in Machine Learning\\n'\n",
      " 'There are many different techniques and algorithms used in machine learning, '\n",
      " 'each with its own strengths and weaknesses. In this section, we will provide '\n",
      " 'an overview of some of the most commonly used algorithms, such as linear '\n",
      " 'regression, decision trees, support vector machines, and neural networks. We '\n",
      " 'will also discuss the importance of data preprocessing, feature engineering, '\n",
      " 'and model evaluation in the machine learning pipeline, as well as the '\n",
      " 'ethical considerations and challenges associated with developing and '\n",
      " 'deploying machine learning systems.\\n'\n",
      " '\\n'\n",
      " 'Section 4: The Future of Machine Learning\\n'\n",
      " 'As machine learning continues to advance and evolve, the possibilities for '\n",
      " 'its future are endless. In this final section, we will explore some of the '\n",
      " 'emerging trends and technologies in machine learning, such as deep learning, '\n",
      " 'transfer learning, and federated learning. We will also discuss the '\n",
      " 'potential impact of machine learning on society, including issues related to '\n",
      " 'bias, privacy, and job displacement. By understanding the wonders of machine '\n",
      " 'learning and its implications for the future, we can better prepare '\n",
      " 'ourselves for the opportunities and challenges that lie ahead.')\n"
     ]
    }
   ],
   "source": [
    "chain = SimpleSequentialChain(chains=[title_chain, sections_chain], verbose=True)\n",
    "\n",
    "pprint(chain.run(\"Machine Learning\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be an interesting blog!\n",
    "\n",
    "This concludes our introduction to LangChain basics. \n",
    "\n",
    "I hope you had some fun and learnd something new. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
